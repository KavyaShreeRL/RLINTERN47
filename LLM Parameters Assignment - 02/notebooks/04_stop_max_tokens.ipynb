{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b75f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "print(\" Stop Sequences & Max Tokens Explorer Ready!\")\n",
    "\n",
    "\n",
    "prompt = \"Generate a dialogue between User and Assistant.\"\n",
    "\n",
    "print(\" Stop Sequences & Max Tokens Experiment\")\n",
    "print(f\"Prompt: '{prompt}'\\n\")\n",
    "\n",
    "configs = [\n",
    "    (None, 50, \"No stop, 50 tokens\"),\n",
    "    (None, 200, \"No stop, 200 tokens\"), \n",
    "    ([\"User:\"], 50, \"Stop at 'User:', 50 tokens\"),\n",
    "    ([\"User:\"], 200, \"Stop at 'User:', 200 tokens\")\n",
    "]\n",
    "\n",
    "for stop_seq, max_tokens, desc in configs:\n",
    "    print(f\" {desc}:\")\n",
    "    \n",
    "    api_params = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "    \n",
    "    if stop_seq:\n",
    "        api_params[\"stop\"] = stop_seq\n",
    "    \n",
    "    response = client.chat.completions.create(**api_params)\n",
    "    \n",
    "    print(f\"Result ({response.choices[0].finish_reason}, {response.usage.completion_tokens} tokens):\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
